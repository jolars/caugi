---
title: "Performance"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.width = 5,
  warning = FALSE
)
```

This vignette discusses the performance characteristics of `caugi` including a comparison to the popular [`igraph`](https://r.igraph.org/), [`bnlearn`](https://www.bnlearn.com/), [`dagitty`](https://dagitty.net/), and [`ggm`](https://cran.r-project.org/package=ggm).
We focus on the practical trade-offs that arise from different core data structures and design choices.

The headline is: `caugi` frontloads computation.
That is, `caugi` spends more effort when constructing a graph and preparing indexes, so that queries are wicked fast. The high performance is also due to the Rust backend.

### Design choices

#### Compressed Sparse Row (CSR) representation

The core data structure in `caugi` is a compressed sparse row (CSR) representation of the graph.
CSR representations store for each vertex a contiguous slice of neighbor IDs with a pointer (offset) array that marks the start/end of each slice.
This format is memory efficient for sparse graphs. The `caugi` graph object also stores important query information in the object, leading to parent, child, and neighbor queries being done in $\mathcal{O}(1)$. This yields a larger memory footprint, but the trade-off is that queries are extremely fast.

#### Mutation and lazy building

The `caugi` graph objects are expensive to build. This is the performance downside of using `caugi`. For each time we make a modification to a `caugi` graph object, we need to rebuild the graph completely since the graph object is immutable by design. This has complexity $\mathcal{O}(|V| + |E|)$, where $V$ is the vertex set and $E$ is the edge set. 

However, the graph object will only be rebuilt when the user either calls `build()` directly or queries the graph. Therefore, you do not need to worry about wasting compute time by iteratively making changes to a `caugi` graph object, as the graph rebuilds lazily when queried. By doing this, `caugi` graphs _feel_ mutable, but, in reality, they are not. 

By doing it this way, we ensure 
- that the graph object is always in a consistent state when queried, and
- that queries are as fast as possible,
while keeping the user experience smooth.

### Comparison
#### Setup

```{r setup}
set.seed(42)
```

We are limiting ourselves to comparing graphs up to size $n = 1000$, as the conversion to `bnlearn` and `dagitty` become prohibitively slow for larger graphs.

```{r generate-graph}
generate_graphs <- function(n, p) {
  cg <- caugi::generate_graph(n = n, p = p, class = "DAG")
  ig <- caugi::as_igraph(cg)
  ggmg <- caugi::as_adjacency(cg)
  bng <- caugi::as_bnlearn(cg)
  dg <- caugi::as_dagitty(cg)
  list(cg = cg, ig = ig, ggmg = ggmg, bng = bng, dg = dg)
}
```

#### Relational queries

We start with parents/children:

```{r benchmark-parents-children}
#| fig-cap: "Benchmarking parents/children queries for different packages."
graphs <- generate_graphs(1000, p = 0.25) # dense graph
cg <- graphs$cg
ig <- graphs$ig
ggmg <- graphs$ggmg
bng <- graphs$bng
dg <- graphs$dg

test_node_index <- sample(1000, 1)
test_node_name <- paste0("V", test_node_index)

bm_parents_children <- bench::mark(
  caugi = {
    caugi::parents(cg, test_node_name)
    caugi::children(cg, test_node_name)
  },
  igraph = {
    igraph::neighbors(ig, test_node_name, mode = "in")
    igraph::neighbors(ig, test_node_name, mode = "out")
  },
  bnlearn = {
    bnlearn::parents(bng, test_node_name)
    bnlearn::children(bng, test_node_name)
  },
  ggm = {
    ggm::pa(test_node_name, ggmg)
    ggm::ch(test_node_name, ggmg)
  },
  dagitty = {
    dagitty::parents(dg, test_node_name)
    dagitty::children(dg, test_node_name)
  },
  check = FALSE # igraph returns igraph object
)

plot(bm_parents_children)
```

As you can see, `bnlearn` performs best for this particular example.
In our next experiment, however, we will examine if this
extends to different graph sizes and densities, by parameterizing
our benchmark over `n` and `p`. Note that we adjust `p` as a function
of `n` to keep the graphs reasonably sparse.

```{r benchmark-parents-children-parameterized}
bm_parents_children_np <-
  bench::press(
    n = c(10, 100, 500, 1000, 5000, 10000),
    p = c(0.5, 0.9),
    {
      p_mod <- 10 * log10(n) / n * p
      graphs <- generate_graphs(n, p = p_mod)
      cg <- graphs$cg
      ig <- graphs$ig
      ggmg <- graphs$ggmg
      bng <- graphs$bng
      dg <- graphs$dg

      test_node_index <- sample(n, 1)
      test_node_name <- paste0("V", test_node_index)

      bench::mark(
        caugi = {
          caugi::parents(cg, test_node_name)
          caugi::children(cg, test_node_name)
        },
        igraph = {
          igraph::neighbors(ig, test_node_name, mode = "in")
          igraph::neighbors(ig, test_node_name, mode = "out")
        },
        bnlearn = {
          bnlearn::parents(bng, test_node_name)
          bnlearn::children(bng, test_node_name)
        },
        ggm = {
          ggm::pa(test_node_name, ggmg)
          ggm::ch(test_node_name, ggmg)
        },
        dagitty = {
          dagitty::parents(dg, test_node_name)
          dagitty::children(dg, test_node_name)
        },
        check = FALSE # igraph returns igraph object
      )
    },
    .quiet = TRUE
  )
```

Next, we plot the benchmark results. As you can see, `bnlearn` performs
worse as graph size and density increases, whereas `caugi` is almost
unaffected by these parameters, outperforming all other packages when
graphs get larger and denser. `dagitty` and `ggm` perform worst overall,
quickly becoming infeasible for larger graphs.

```{r}
#| fig-cap: "Parameterized benchmarking of parents/children queries."
#| echo: false
#| fig-width: 7
plot_parameterized_benchmark <- function(bm) {
  library(ggplot2)

  bm_mod <- within(
    bm,
    {
      expr <- as.character(expression)
      median <- as.numeric(median)
    }
  )

  ggplot(bm_mod, aes(n, median, color = expr)) +
    geom_line() +
    geom_point() +
    scale_y_log10() +
    facet_wrap(~p, labeller = "label_both") +
    labs(y = "time (s)", color = NULL)
}

plot_parameterized_benchmark(bm_parents_children_np)
```

For ancestors and descendants, we see that `caugi` outperforms all other packages by a several magnitudes, except for `igraph`, which it still beats, but by a smaller margin:

```{r benchmark-an-de}
#| fig-cap: "Benchmarking ancestors/descendants queries for different packages."
bm_ancestors_descendants <- bench::mark(
  caugi = {
    caugi::ancestors(cg, "V500")
    caugi::descendants(cg, "V500")
  },
  igraph = {
    igraph::subcomponent(ig, "V500", mode = "in")
    igraph::subcomponent(ig, "V500", mode = "out")
  },
  bnlearn = {
    bnlearn::ancestors(bng, "V500")
    bnlearn::descendants(bng, "V500")
  },
  dagitty = {
    dagitty::ancestors(dg, "V500")
    dagitty::descendants(dg, "V500")
  },
  check = FALSE # dagitty returns V500 as well and igraph returns an igraph
)

plot(bm_ancestors_descendants)
```

#### D-separation

Using the graph from before, we obtain a valid adjustment set and then check for d-separation.

```{r benchmark-d-sep-setup}
valid_adjustment_set <- caugi::adjustment_set(
  cg,
  "V500",
  "V681",
  type = "backdoor"
)
valid_adjustment_set
```

```{r benchmark-d-sep}
#| fig-cap: "Benchmarks for obtaining a valid adjustment set for d-separation."
bm_dsep <- bench::mark(
  caugi = caugi::d_separated(cg, "V500", "V681", valid_adjustment_set),
  bnlearn = bnlearn::dsep(bng, "V500", "V681", valid_adjustment_set),
  dagitty = dagitty::dseparated(dg, "V500", "V681", valid_adjustment_set)
)

plot(bm_dsep)
```

#### Subgraph (building)

Here we see an example of where the frontloading hurts performance. When we build a subgraph, we have to rebuild the entire `caugi` graph object. Here, we see that while `caugi` outperforms other packages for queries (except for parents/children for `bnlearn`), it is slower for building the graph objects themselves, which shows in the subgraph benchmark:

```{r benchmark-subgraph}
#| fig-cap: "Benchmarking subgraph extraction for different packages."
subgraph_nodes_index <- sample.int(1000, 500)
subgraph_nodes <- paste0("V", subgraph_nodes_index)

bm_subgraph <- bench::mark(
  caugi = {
    caugi::subgraph(cg, subgraph_nodes)
  },
  igraph = {
    igraph::subgraph(ig, subgraph_nodes)
  },
  bnlearn = {
    bnlearn::subgraph(bng, subgraph_nodes)
  },
  check = FALSE
)

plot(bm_subgraph)
```


### Session info

```{r session-info}
sessionInfo()
```
